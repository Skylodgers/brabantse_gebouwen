{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f0ed3d9-970b-4cd7-b1c2-052e114505e3",
   "metadata": {},
   "source": [
    "## Cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbf0952-c2ca-4665-b3f1-840969562e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import uuid\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import shutil\n",
    "import csv\n",
    "\n",
    "lookup_path = './lookup/'\n",
    "source_path = './out/'\n",
    "mappings_path = './mappings/'\n",
    "#save_path = '../../../../digipolis-arches-shoku-pkg/source/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af069a79-928f-4753-9f61-9b269a13f3c6",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b146693-6a72-4cd1-98fa-36868f59e854",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resource_identifier(source_id):\n",
    "    return str(uuid.uuid5(uuid.NAMESPACE_DNS, source_id))\n",
    "\n",
    "\n",
    "def generate_uri(source_id):\n",
    "    return str(f'https://www.geonames.org/{source_id}')\n",
    "\n",
    "\n",
    "def coordinates_geo_json(source_value):    \n",
    "    return f'POINT {source_value}'.replace(\",\", \"\")\n",
    "\n",
    "\n",
    "def coordinates_wkt(source_value):    \n",
    "    return f'{source_value}'.replace(\",\", \"\")\n",
    "\n",
    "\n",
    "def get_constants(node_mapping):\n",
    "    constant_dict = {}\n",
    "    constants = node_mapping['constants']\n",
    "    for constant in constants:\n",
    "        for constant_label, value in constant.items():\n",
    "            constant_dict[constant_label] = value\n",
    "    return constant_dict\n",
    "\n",
    "\n",
    "def lookup(code, lookup_file):\n",
    "    lookup_df = pd.read_csv(lookup_path + lookup_file)\n",
    "    try:\n",
    "        concept_name = lookup_df[lookup_df['code'] == code]['concept'].iloc[0]\n",
    "        return concept_name\n",
    "    except:\n",
    "        print(f'{code} NOT FOUND IN {lookup_file}')\n",
    "        return f'{code} NOT FOUND IN {lookup_file}'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa61819-c08e-414f-b79a-90a4924ad24d",
   "metadata": {},
   "source": [
    "## Save csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1416dc-9d4b-4d34-8e7a-b27b1e566e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_mapped_set(source_df, _package, _resource_model, _card):\n",
    "    \n",
    "    package = _package.split('_')[1]     \n",
    "    \n",
    "    file_name = '%s/%s/%s/%s.csv' % (save_path, package, _resource_model, _card)\n",
    "    source_df.to_csv(file_name, index=False)    \n",
    "    del source_df\n",
    "    return 'Saved OK'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad915d97-5e7b-412e-99e3-801e95a1d7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def related_resource(source_value):\n",
    "    resourceid = str(uuid.uuid5(uuid.NAMESPACE_DNS, source_value))\n",
    "    resourceXresourceId = str(uuid.uuid5(uuid.NAMESPACE_DNS, source_value + 'relation'))\n",
    "    relation = '[{\"resourceId\": \"%s\", \"ontologyProperty\": \"\", \"resourceXresourceId\": \"%s\", \"inverseOntologyProperty\": \"\"}]' % (resourceid, resourceXresourceId)\n",
    "    return relation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3921ba85-2f16-4258-be06-60e688fe41d8",
   "metadata": {},
   "source": [
    "## Mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9003c690-7de8-4885-b3d1-2f8d95302dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mapping(source_list, node_mappings, graph, dataset, card_name, card_order):\n",
    "\n",
    "    obj_dict = {}\n",
    "    obj_list = []\n",
    "    for obj in source_list:        \n",
    "        \n",
    "        for node_mapping in node_mappings:\n",
    "            \n",
    "            if node_mapping['from'] in obj.keys():\n",
    "                \n",
    "                if 'resource_id' in node_mapping.keys():\n",
    "                    obj_dict['ResourceID'] = resource_identifier(str(obj[node_mapping['from']]))\n",
    "                    obj_dict['card'] = card_name\n",
    "                    obj_dict['card_order'] = card_order\n",
    "                    \n",
    "                if 'constants' in node_mapping.keys():\n",
    "                    obj_dict[node_mapping['to']] = obj[node_mapping['from']]  \n",
    "                    obj_dict.update(get_constants(node_mapping))\n",
    "                               \n",
    "                if 'function' in node_mapping.keys():\n",
    "                    \n",
    "                    # OBS, try: result = globals()[func_name]()\n",
    "                    \n",
    "                    if node_mapping['function']['name'] == 'generate_uri':\n",
    "                        obj_dict[node_mapping['to']] = generate_uri(obj[node_mapping['from']])                                            \n",
    "                    \n",
    "                    if node_mapping['function']['name'] == 'lookup':\n",
    "                        obj_dict[node_mapping['to']] = lookup(obj[node_mapping['from']], node_mapping['function']['args']['lookup_file'])                                            \n",
    "                    \n",
    "                    if node_mapping['function']['name'] == 'related_resource':\n",
    "                        obj_dict[node_mapping['to']] = related_resource(obj[node_mapping['from']])      \n",
    "\n",
    "                    if node_mapping['function']['name'] == 'coordinates_geo_json':\n",
    "                        obj_dict[node_mapping['to']] = coordinates_geo_json(obj[node_mapping['from']])      \n",
    "                    \n",
    "                    if node_mapping['function']['name'] == 'coordinates_wkt':\n",
    "                        obj_dict[node_mapping['to']] = coordinates_wkt(obj[node_mapping['from']])      \n",
    "                else:\n",
    "                    obj_dict[node_mapping['to']] = obj[node_mapping['from']]  \n",
    "        \n",
    "        obj_list.append(obj_dict)\n",
    "        obj_dict = {}\n",
    "        \n",
    "    source_df = pd.DataFrame(obj_list)\n",
    "    number_of_records = len(obj_list)\n",
    "    if number_of_records > 0:\n",
    "        #save_it = save_mapped_set(source_df, package, resource_model, card)\n",
    "        source_df.to_csv(f'out/{card_name}_mapped.csv', index =False)\n",
    "        \n",
    "\n",
    "    #return '%s saved: %s' % (card_name, number_of_records)\n",
    "    return obj_list\n",
    "\n",
    "\n",
    "#relation = '[{\"resourceId\": \"%s\", \"ontologyProperty\": \"\", \"resourceXresourceId\": \"%s\", \"inverseOntologyProperty\": \"\"}]' % (usr_dict['ResourceID_mat'] , uuid.uuid4())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49af7a3-e878-4424-8527-343cd44e126d",
   "metadata": {},
   "source": [
    "## Generate dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b92b8c-4fb4-4c7b-ac65-8c40f8f7b7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "with open(mappings_path + 'mappings_geonames.json') as f:\n",
    "    mappings_dict = json.load(f)  \n",
    "    \n",
    "    record_dict = {}\n",
    "    record_list = []\n",
    "\n",
    "    single_list = []\n",
    "    alternate_name_list = []\n",
    "    digital_reference_list = []\n",
    "\n",
    "    mappings = mappings_dict['mappings']\n",
    "    name = mappings_dict['name']\n",
    "    graph = mappings_dict['graph']\n",
    "    print('-', name)\n",
    "    print('  -', graph)\n",
    "    \n",
    "    for mapping in mappings:  \n",
    "        dataset = mapping['dataset']\n",
    "        \n",
    "        for card in mapping['cards']:      \n",
    "            card_name = card['card_name']\n",
    "            card_order = card['card_order']\n",
    "            node_mappings = card['node_mappings']\n",
    "            \n",
    "            # list of all keys to be able to dump all source fields not in the mapping\n",
    "            node_mappings_keys = [item['from'] for item in card['node_mappings']]\n",
    "            \n",
    "            # read file, DictReader to preserve order\n",
    "            records = csv.DictReader(open(f'{source_path}{dataset}', encoding='utf-8-sig'), delimiter=',')\n",
    "\n",
    "            exclude_list = ['post', 'link', 'unlc', 'wkdt', 'unic', 'iata']\n",
    "            #if 'isolanguage' in record.keys() and record['isolanguage'] not in exclude_list:\n",
    "            \n",
    "            for record in records:\n",
    "                ## add filter from mapping!\n",
    "                \n",
    "                for mapping_key in node_mappings_keys:                \n",
    "                    if mapping_key in record.keys():\n",
    "                        if len(record[mapping_key]) > 0:                                \n",
    "                            record_dict[mapping_key] = record[mapping_key]\n",
    "                    \n",
    "                record_list.append(record_dict)                            \n",
    "                record_dict = {}                   \n",
    "\n",
    "            if card_name == 'single':                \n",
    "                single_list.extend(record_list)                    \n",
    "            if card_name == 'alternate_name':\n",
    "                alternate_name_list.extend(record_list)                    \n",
    "            if card_name == 'digital_reference':\n",
    "                digital_reference_list.extend(record_list)                    \n",
    "                        \n",
    "            record_list = []     \n",
    "\n",
    "\n",
    "        \n",
    "        if len(single_list) > 0:\n",
    "            Single = make_mapping(single_list, node_mappings, graph, dataset, card_name, card_order)\n",
    "            print('    -', \"Single\", len(Single))\n",
    "\n",
    "        if len(alternate_name_list) > 0:\n",
    "            AlternateName = make_mapping(alternate_name_list, node_mappings, graph, dataset, card_name, card_order)\n",
    "            print('    -', \"AlternateName\", len(AlternateName))\n",
    "\n",
    "        if len(digital_reference_list) > 0:\n",
    "            DigitalReference = make_mapping(digital_reference_list, node_mappings, graph, dataset, card_name, card_order)\n",
    "            print('    -', \"DigitalReference\", len(DigitalReference))\n",
    "\n",
    "\n",
    "print('---------') \n",
    "print(datetime.datetime.now())\n",
    "#%reset -f "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e5173b-5f58-440c-8375-e8b1d5625ce6",
   "metadata": {},
   "source": [
    "# Merge Cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8c230a-1b05-40e6-98fc-f206c6bf324a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Single_df = pd.DataFrame(Single)\n",
    "AlternateName_df = pd.DataFrame(AlternateName)\n",
    "\n",
    "geonames_df = pd.concat([\n",
    "    Single_df,\n",
    "    Alternate_df\n",
    "])\n",
    "\n",
    "sorted_geonames_df = geonames_df.sort_values(by=['ResourceID', 'card_order'])\n",
    "sorted_geonames_df.to_csv('./out/geonames_mapped.csv', index=False)\n",
    "sorted_geonames_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91feb2b5-47a8-46a0-b326-394c95a71fc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
